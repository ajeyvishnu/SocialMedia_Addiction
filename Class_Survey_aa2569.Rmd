---
title: "Class_Survey_aa2569"
author: "aa2569@scarletmail.rutgers.edu"
date: "4/17/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---
  
## Loading the Dataset
  
```{r}
library(readr)
library(MVA)
library(HSAUR2)
library(SciViews)
library(scatterplot3d)
library(car)
library(lattice)
library(GGally)
library(ggplot2)
library(ggridges)
library(ggvis)
library(ggthemes)
library(cowplot)
library(gapminder)
library(gganimate)
library(dplyr)
library(tidyverse)
library(grid)
library(gridExtra)
library(RColorBrewer)
library(Hotelling)
library(stats)
library(biotools)
library(factoextra)
library(FactoMineR)
library(ggfortify)
library(psych)
library(corrplot)
library(devtools)
library(cluster)
library(magrittr)
library(NbClust)
library(MASS)
library(gvlma)
library(leaps)
library(relaimpo)
library(e1071)
library(pROC)
library(memisc)
library(ROCR)
library(klaR)
library(caret)
library(caTools)

sm_data <- read.csv("/Users/ajayvishnu/Desktop/RUTGERS/Spring_2023/Multivariate Analysis/Datasets/Class_Survey.csv")

sm <- sm_data[,c(3:15)]

boxplot(sm, main = "Box Plot - All Variables", ylab = "Value", par(cex.lab = 0.5))

sm_new <- sm_data[,c(3,4,5,12,14,15)]
```

* The data is collected from a class of 25 students who have reported their usage of social media apps for seven weeks.
* The data has 15 columns and 175 rows in total.
* The data is not cumulated for each student. Instead, we have considered each row as an individual data entry for better analysis.
* The data dictionary is mentioned below.
* For the analysis, we have excluded columns 1,2, and 14. Columns 1 & 2 are Name and Week number which we can exclude. We exclude column 14 as well as it is just the summation of all the other individual social media apps.
* The boxplot shows that the columns Telegram, Facebook, TikTok, WeChat, Twitter have a lot of outliers, this is because we have very few students who use this chats.

### Two Approaches

* As we have many outliers, we can try to analyse the data in two different methods and check if there is any difference.
* We can consider two approaches - One considering all the Data, One considering only the columns WhatsApp, Instagram, Snapchat, LinkedIn, Total Social Media hours, and Addiction.

## QUESTIONS and HYPOTHESIS

### Questions

#### Based on the given variables, can we classify if the student is addicted to Social Media or not?
#### Based on the given variables, can we predict if the student is addicted to Social Media or not?

### Hypothesis

#### We can predict if the student is addicted to social media based on the time they have spent of the individual social media apps.

## Analysing the Data

```{r}
str(sm)
```

* We have converted the Addiction column (column 15) to 1 and 0 - 1 being Addicted and 0 being not addicted.
* This will be used for the prediction model that we built.

### Data Dictionary

* Student - Name of the Student
* Week - Week start and end date
* Whatsapp - Time spent on Whatsapp per week(hrs)
* Instagram - Time spent on Instagram per week(hrs)
* Snapchat - Time spent on Snapchat per week(hrs)
* Telegram - Time spent on Telegram per week(hrs)
* Facebook/Messenger - Time spent on Facebook/Messenger per week(hrs)
* BeReal - Time spent on BeReal per week(hrs)
* TikTok - Time spent on Tiktok per week(hrs)
* Wechat - Time spent on WeChat per week(hrs)
* Twitter - Time spent on Twitter per week(hrs)
* Linkedin - Time spent on LinkedIn per week(hrs)
* Messages - Time spent on Messages per week(hrs)
* Total Social Media Screen Time - Total time spent on social media per week(hrs)
* Social Media Addiction Level - Is the person addicted to social media?	
# Times opened >= 105 - Addicted
# Times opened < 105 - Not Addicted
# Considering the 24-hour slots in a day, how many hour slots did the user open social media apps? This is for one day. 
# Consider the above count and add the daily counts over the week and input that data

### Correlation Test

#### Main Dataset

```{r}
corrplot(cor(sm), type = "upper", method = "color")
```

#### New Dataset

```{r}
corrplot(cor(sm_new), type = "upper", method = "color")
```

* The correlation matrix shows us that there is correlation between the columns in both cases.
* Hence, Principal Component Analysis (PCA) can be used to reduce the number of columns for the analysis.

## Principal Component Analysis (PCA)

###PCA

```{r}
sm_pca <- prcomp(sm[,1:11],scale=TRUE)
sm_new_pca <- prcomp(sm_new[,-6],scale=TRUE)
```

* We have excluded the last column which is the addiction (Addicted/Not addicted) as we are trying answer the question on how to classify the students.

### Scree diagram

#### Main Dataset

```{r}
fviz_eig(sm_pca, addlabels = TRUE)
```

* The scree diagram shows us that sum of the first 2 principal components is less than 70%.
* So, we cannot move forward using PCA for column reduction.
* We now move on to check EFA for this main dataset.

#### New Dataset

```{r}
fviz_eig(sm_new_pca, addlabels = TRUE)
```

* The scree diagram shows us that sum of the first 2 principal components is 76%.
* So, we can use PCA for column reduction.
* No need to consider EFA for this approach as there are already less columns (5) in this dataset.

##### PCA Values (New Dataset)

```{r}
pca_data <- as.data.frame(sm_new_pca$x)
pca_data <- pca_data[,1:2]
```

* We can use this dataset for our cluster analysis later for this approach.

## Exploratory Factor Analysis (EFA)

### EFA

```{r}
fit.sm <- principal(sm[,1:11], nfactors=5, rotate="varimax")
fa.diagram(fit.sm)
```

### Defining the factors obtained

#### RC1
* Both WeChat and Tiktok are popular apps in Asia region specifically.
* WeChat has multiple uses for chatting, payments, whereas Tiktok is used only for social media purpose to share and view videos.

#### RC2
* Snapchat, LinkedIn, Instagram, Telegram are popular all over the world.
* LinkedIn is used for professional purposes. Snapchat, Telegram are used for chatting and Instagram is used for posting photos and videos.

#### RC3
* Twitter & Facebook are popular all over the world.
* Both are used for posting photos and videos.

#### RC4
* WhatsApp is popular world wide and BeReal is a new app that has entered the social media market.

#### RC5
* RC5 has only one variable  pertaining to it.
* So, we excluding the RC5 and consider the Messages column directly.

### Defining new columns through EFA

```{r}
efa_data <- as.data.frame(fit.sm$scores)
efa_data <- efa_data[,-5]
efa_data$C5 <- sm$Messages..hrs.
```

## Clustering

### Kmeans optimal clusters

* As we have two factors, Addicted and Not Addicted, we check the clustering for 2 clusters only.

#### Main Dataset

```{r}
set.seed(42)
matstd_sm <- scale(efa_data)

km.res <- kmeans(matstd_sm, 2, nstart = 10)

fviz_cluster(km.res, data = matstd_sm,
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal())
```

* We have used the efa_data for the clustering of the forst approach.
* We can check the precision and recall using the confusion matrix below.

```{r}
Clustered <- ifelse(km.res$cluster > 1.5, "Not Addicted", "Addicted")
Actual <- ifelse(sm$Social.Media.Addiction == 1, "Addicted", "Not Addicted")
confusion_mat <- table(Clustered, Actual)
confusion_mat
accuracy <- sum(diag(confusion_mat)) / sum(confusion_mat)
precision <- confusion_mat[2, 2] / sum(confusion_mat[, 2])
recall <- confusion_mat[2, 2] / sum(confusion_mat[2, ])
cat("Accuracy:", round(accuracy, 3), "\n")
cat("Precision:", round(precision, 3), "\n")
cat("Recall:", round(recall, 3), "\n")
```

* Although we have a recall of 1, we can see that the confusion matrix shows the clustering is done in a way where almost all the users are Addicted.
* This shows that we cannot classify our data into Addicted and Not addicted based on the variables given.
* We can now check the clustering using the second approach.

#### New Dataset

```{r}
set.seed(42)
matstd_sm1 <- scale(pca_data)

km.res1 <- kmeans(matstd_sm1, 2, nstart = 10)

fviz_cluster(km.res1, data = matstd_sm1,
             ellipse.type = "convex",
             palette = "jco",
             ggtheme = theme_minimal())
```

* We have used the pca_data for the clustering of the forst approach.
* We can check the precision and recall using the confusion matrix below.

```{r}
Clustered1 <- ifelse(km.res1$cluster > 1.5, "Not Addicted", "Addicted")
Actual <- ifelse(sm$Social.Media.Addiction == 1, "Addicted", "Not Addicted")
confusion_mat1 <- table(Clustered1, Actual)
confusion_mat1
accuracy1 <- sum(diag(confusion_mat1)) / sum(confusion_mat1)
precision1 <- confusion_mat1[2, 2] / sum(confusion_mat1[, 2])
recall1 <- confusion_mat1[2, 2] / sum(confusion_mat1[2, ])
cat("Accuracy:", round(accuracy1, 3), "\n")
cat("Precision:", round(precision1, 3), "\n")
cat("Recall:", round(recall1, 3), "\n")
```

* The precision is obtained to be 80% which is not so bad.
* Yet, we see that 55 inputs who are addicted to social media have been clustered to not addicted.
* This shows that we cannot classify our data into Addicted and Not addicted based on the variables given.

## Classification Summary

#### Considering both the approaches, we can see that we cannot classify the data into addicted and not addicted.
#### Answer to our question 1: No, we cannot classify.

## Logistic Regression

* To answer our question 2, we perform logistic regression as we have only 2 variable factors (Addicted/Not Addicted)

```{r}
str(sm)
```

* The str function shows the data types of each of the variable
* Here, we are comparing the type of university and the acceptance rate.
* Hence, we need to give them a character name and convert them into a factor for the analysis.

#### Main Dataset

##### Training and Testing

```{r}
set.seed(123)
split = sample.split(sm$Social.Media.Addiction, SplitRatio = 0.70)
train_sm = subset(sm, split == TRUE)
test_sm = subset(sm, split == FALSE)

Xtrain_sm <- train_sm[,1:11]
Ytrain_sm <- train_sm[,13]

Xtest_sm <- test_sm[,1:11]
```

* We consider the training and testing data with a 70-30 split.

##### Regression

```{r}
x_sm <- cbind(Xtrain_sm,Ytrain_sm)
logistic_sm <- glm(Ytrain_sm ~ ., data = x_sm,family='binomial')
summary(logistic_sm)
```

* The regression summary shows that we have significant variables that affect the output variable.
* We check the confusion matrix, precision and recall of our regression below.

##### Confusion Matrix, Precision

```{r}
probabilities_sm2 <- predict(logistic_sm, newdata = Xtest_sm, type = "response")

predicted_sm2 <- ifelse(probabilities_sm2 > 0.5, "Yes", "No")
actual_sm <- ifelse(test_sm$Social.Media.Addiction == 1, "Yes", "No")
confusion_sm2 <- table(predicted_sm2, actual_sm)
confusion_sm2
accuracy2 <- sum(diag(confusion_sm2)) / sum(confusion_sm2)
precision2 <- confusion_sm2[2, 2] / sum(confusion_sm2[, 2])
recall2 <- confusion_sm2[2, 2] / sum(confusion_sm2[2, ])
cat("Accuracy:", round(accuracy2, 3), "\n")
cat("Precision:", round(precision2, 3), "\n")
cat("Recall:", round(recall2, 3), "\n")
```

* Precision we got for the first approach is good with 86.7%

##### ROC and AUC

```{r}
roc_sm <- roc(test_sm$Social.Media.Addiction, probabilities_sm2)
auc_sm <- auc(roc_sm)

ggroc(roc_sm, color = "blue", legacy.axes = TRUE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "False Positive Rate", y = "True Positive Rate",
       title = paste("ROC Curve (AUC = ", round(auc_sm, 2), ")")) +
  annotate("text", x = 0.5, y = 0.5, label = paste0("AUC = ", round(auc_sm, 2)))
```

* AUC of the ROC curve = 85%
* Considering both AUC of the ROC curve of 85% and a precision of 86.7% we can say that the regression model works well and we will be able to predict the if the student is addicted to social media or not based on the variables provided.
* We can now check how the logistic regression for the second approach works.

#### New Dataset

##### Training and Testing

```{r}
set.seed(123)
split = sample.split(sm_new$Social.Media.Addiction, SplitRatio = 0.70)
train_sm_new = subset(sm_new, split == TRUE)
test_sm_new = subset(sm_new, split == FALSE)

Xtrain_sm_new <- train_sm_new[,1:5]
Ytrain_sm_new <- train_sm_new[,6]

Xtest_sm_new <- test_sm_new[,1:5]
```

* We consider the training and testing data with a 70-30 split.

##### Regression

```{r}
x_sm_new <- cbind(Xtrain_sm_new,Ytrain_sm_new)
logistic_sm_new <- glm(Ytrain_sm_new ~ ., data = x_sm_new,family='binomial')
summary(logistic_sm_new)
```

* The regression summary shows that we have significant variables that affect the output variable.
* We check the confusion matrix, precision and recall of our regression below.

```{r}
probabilities_sm3 <- predict(logistic_sm_new, newdata = Xtest_sm_new, type = "response")

predicted_sm3 <- ifelse(probabilities_sm3 > 0.5, "Yes", "No")
actual_sm <- ifelse(test_sm_new$Social.Media.Addiction == 1, "Yes", "No")
dim(predicted_sm3)
confusion_sm3 <- table(predicted_sm3, actual_sm)
confusion_sm3
accuracy3 <- sum(diag(confusion_sm3)) / sum(confusion_sm3)
precision3 <- confusion_sm3[2, 2] / sum(confusion_sm3[, 2])
recall3 <- confusion_sm3[2, 2] / sum(confusion_sm3[2, ])
cat("Accuracy:", round(accuracy3, 3), "\n")
cat("Precision:", round(precision3, 3), "\n")
cat("Recall:", round(recall3, 3), "\n")
```

* Precision we got for the first approach is good with 83.3%.

```{r}
roc_sm_new <- roc(test_sm_new$Social.Media.Addiction, probabilities_sm3)
auc_sm_new <- auc(roc_sm_new)
auc_sm_new

ggroc(roc_sm_new, color = "blue", legacy.axes = TRUE) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  scale_x_continuous(labels = scales::percent_format()) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(x = "False Positive Rate", y = "True Positive Rate",
       title = paste("ROC Curve (AUC = ", round(auc_sm_new, 2), ")")) +
  annotate("text", x = 0.5, y = 0.5, label = paste0("AUC = ", round(auc_sm_new, 2)))
```

* AUC of the ROC curve = 83%
* Considering both AUC of the ROC curve of 83% and a precision of 83.3% we can say that the regression model works well and we will be able to predict the if the student is addicted to social media or not based on the variables provided (Only 5 columns in this approach compared to 12 in the first approach)

## Regression Summary

#### Considering both the approaches, we can see that we can predict if the student is addicted to social media based on the input variables.
#### Answer to our question 2: Yes, we can predict.
#### Our hypothesis that we can predict the addiction can be proved right.

